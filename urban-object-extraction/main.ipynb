{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1y10c6h2j--cnvQaCwZqiFLLKS0aD4fbN?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aiqCsozA5pqn"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This Colab notebook presents a comprehensive approach to building a powerful neural network model for semantic segmentation, a fundamental task in computer vision. Semantic segmentation involves assigning a specific class label to each pixel in an image, enabling detailed understanding and precise localization of objects or semantic concepts within the visual scene.\n",
        "\n",
        "The notebook provides step-by-step instructions and code implementation for various stages of the project. We begin by loading and preprocessing the dataset, which is a crucial step in ensuring the dataset's quality and suitability for training our model. We address common challenges such as noisy annotations, class imbalance, and inconsistent labeling, ensuring that our dataset is clean and representative.\n",
        "\n",
        "Next, we delve into the architecture design of our neural network model. Leveraging the power of convolutional neural networks (CNNs), we construct a deep learning model capable of capturing fine-grained details and spatial dependencies present in the images. The notebook demonstrates the implementation of advanced architectural designs, enabling our model to achieve state-of-the-art performance in semantic segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJsQQcBAdF7O",
        "outputId": "b9e14bc1-dfc5-4677-d8f0-0e9541a9b3d8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# from torch.autograd import Variable\n",
        "import torchvision.transforms as tr\n",
        "from skimage import io\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# from scipy.ndimage import zoom\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm as tqdm\n",
        "# from pandas import read_csv\n",
        "# from math import floor, ceil, sqrt, exp\n",
        "# from IPython import display\n",
        "# import time\n",
        "# from itertools import chain\n",
        "import time\n",
        "# import warnings\n",
        "# from pprint import pprint\n",
        "\n",
        "import random\n",
        "\n",
        "# Function for setting the seed\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "print('IMPORTS OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVC_WdfGdF7R",
        "outputId": "5cb10142-5875-47a2-c83c-6989d741c999"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWMrUCfAdF7S",
        "outputId": "35f5cb83-72d8-4754-b1f3-25a8c9e76a37"
      },
      "outputs": [],
      "source": [
        "# Global Variables' Definitions\n",
        "\n",
        "# please change the paths to the dataset accordingly    \n",
        "\n",
        "PATH_TO_DATASET_IMAGES = '/content/drive/MyDrive/Start'\n",
        "PATH_TO_DATASET_LABELS = '/content/drive/MyDrive/Finish'\n",
        "\n",
        "PATH_TO_TRAIN_DATASET_IMAGES = '/content/drive/MyDrive/Dataset2/train/images'\n",
        "PATH_TO_TRAIN_DATASET_LABEL = '/content/drive/MyDrive/Dataset2/train/ground_truth'\n",
        "\n",
        "PATH_TO_VAL_DATASET_IMAGES = '/content/drive/MyDrive/Dataset2/val/images'\n",
        "PATH_TO_VAL_DATASET_LABEL = '/content/drive/MyDrive/Dataset2/val/ground_truth'\n",
        "\n",
        "PATH_TO_TEST_DATASET_IMAGES = '/content/drive/MyDrive/Dataset2/test/images'\n",
        "PATH_TO_TEST_DATASET_LABEL = '/content/drive/MyDrive/Dataset2/test/ground_truth'\n",
        "\n",
        "\n",
        "# please change the costant below to the desidered number\n",
        "BATCH_SIZE = 64\n",
        "PATCH_SIDE = 96\n",
        "N_EPOCHS = 500\n",
        "\n",
        "NORMALISE_IMGS = True\n",
        "\n",
        "LOAD_TRAINED = False\n",
        "\n",
        "DATA_AUG = False\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "print('DEFINITIONS OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSBG5tzKdF7T"
      },
      "outputs": [],
      "source": [
        "def get_tif_images(tif_path):\n",
        "    images = []\n",
        "    for filename in os.listdir(tif_path):\n",
        "        if filename.endswith('.tif'):\n",
        "            images.append(filename)\n",
        "    return images\n",
        "\n",
        "# print(get_tif_images(PATH_TO_DATASET))\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom class to load the dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, img_path, label_path, transform=None, allDataset=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_path (string): path to the folder containing the images\n",
        "            label_path (string): path to the folder containing the labels\n",
        "            transform (callable, optional): Optional transform to be applied on a sample\n",
        "            allDataset (boolean): if True, the dataset is the whole dataset, otherwise it is the train dataset\n",
        "        \"\"\"\n",
        "        # read tif files from tif_path directory\n",
        "        self.transform = transform\n",
        "        self.names = get_tif_images(img_path)\n",
        "        self.color_map = {  (0, 0, 1): 0,\n",
        "                            (0, 1, 1): 1,\n",
        "                            (0, 1, 0): 2,\n",
        "                            (1, 1, 1): 3,\n",
        "                            (1, 1, 0): 4,\n",
        "                            (1, 0, 0): 5}\n",
        "\n",
        "        self.reverse_color_map = {0: (0, 0, 1),\n",
        "                                    1: (0, 1, 1),\n",
        "                                    2: (0, 1, 0),\n",
        "                                    3: (1, 1, 1),\n",
        "                                    4: (1, 1, 0),\n",
        "                                    5: (1, 0, 0)}\n",
        "\n",
        "        self.allDataset=allDataset\n",
        "\n",
        "\n",
        "\n",
        "        self.data = torch.zeros(len(self.names)*len(transform), 3, PATCH_SIDE, PATCH_SIDE)\n",
        "        self.labels = torch.zeros(len(self.names)*len(transform), 1, PATCH_SIDE, PATCH_SIDE, dtype=torch.long)\n",
        "\n",
        "        for idx_transform, transform_element in enumerate(self.transform):\n",
        "            for idx, name in enumerate(self.names):\n",
        "                idx += len(self.names) * idx_transform\n",
        "                img_name = os.path.join(img_path, name)\n",
        "                image = io.imread(img_name)\n",
        "                if allDataset:\n",
        "                    label_name = os.path.join(label_path, name[:-9] + '_label.tif')\n",
        "                else:\n",
        "                  label_name = os.path.join(label_path, self.modify_string(name))\n",
        "                label = io.imread(label_name)\n",
        "                if self.transform:\n",
        "                    image = transform_element(image)\n",
        "                    label = transform_element(label)\n",
        "\n",
        "                # print name of the image and its shape\n",
        "                print('Image name: {} \\t'.format(name))\n",
        "                label = self.convert_image(label)\n",
        "                self.data[idx] = image\n",
        "                self.labels[idx] = label\n",
        "\n",
        "    def modify_string(self, input_str):\n",
        "      parts = input_str.split(\"_\")\n",
        "      parts.remove('IRRG')\n",
        "      parts.insert(-1, \"label\")\n",
        "      return \"_\".join(parts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def convert_image(self, tensor):\n",
        "        \"\"\"\n",
        "        Convert tensor from 3 channel to one channel, and associate it a number from 0 to 5\n",
        "        \"\"\"\n",
        "        converted_tensor = torch.zeros(1, tensor.size(1), tensor.size(2), dtype=torch.long)\n",
        "\n",
        "        for x in range(tensor.size(1)):\n",
        "            for y in range(tensor.size(2)):\n",
        "                pixel_value = tensor[:, x, y]\n",
        "                # apply treshold to pixel value for each channel\n",
        "                for i in range(3):\n",
        "                    if pixel_value[i] < 0.5:\n",
        "                        pixel_value[i] = 0\n",
        "                    else:\n",
        "                        pixel_value[i] = 1\n",
        "\n",
        "                color = self.color_map.get(tuple(pixel_value.tolist()), 0)\n",
        "                converted_tensor[:, x, y] = torch.tensor(color)\n",
        "\n",
        "        # print number of pixels for each class\n",
        "        for i in range(6):\n",
        "            print('Number of pixels for class {}: {}'.format(i, torch.sum(converted_tensor == i)))\n",
        "\n",
        "        return converted_tensor\n",
        "\n",
        "    def revert_image(self, tensor):\n",
        "\n",
        "        converted_tensor = torch.zeros(3, tensor.size(0), tensor.size(1))\n",
        "\n",
        "        for x in range(tensor.size(0)):\n",
        "            for y in range(tensor.size(1)):\n",
        "                pixel_value = tensor[x, y]\n",
        "                # print(pixel_value.tolist(), type(pixel_value.tolist()))\n",
        "\n",
        "                color = self.reverse_color_map.get(pixel_value.tolist(), (0, 0, 0))\n",
        "                converted_tensor[:, x, y] = torch.tensor(color)\n",
        "\n",
        "        return converted_tensor\n",
        "\n",
        "\n",
        "    def normalize(self, mean, std):\n",
        "        for idx in range(len(self.data)):\n",
        "            self.data[idx] = (self.data[idx] - mean) / std\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeWgR4VddF7V",
        "outputId": "f2b57f99-3ab4-46f0-b86b-ad29109333d8"
      },
      "outputs": [],
      "source": [
        "if DATA_AUG:\n",
        "    transform_list_train=[]\n",
        "    transform_list_test=[tr.Compose([tr.ToPILImage(),\n",
        "                                    tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                    tr.ToTensor()])]\n",
        "\n",
        "    for i in range(4):\n",
        "        transform_list_train.append(tr.Compose([tr.ToPILImage(),\n",
        "                                    tr.RandomRotation((90*i,90*i)),\n",
        "                                    tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                    tr.ToTensor()]))\n",
        "    for i in range(4):\n",
        "        transform_list_train.append(tr.Compose([tr.ToPILImage(),\n",
        "                                    tr.RandomRotation((90*i,90*i)),\n",
        "                                    tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                    tr.ToTensor(),\n",
        "                                    tr.RandomHorizontalFlip(p=1)]))\n",
        "    for i in range(4):\n",
        "        transform_list_train.append(tr.Compose([tr.ToPILImage(),\n",
        "                                    tr.RandomRotation((90*i,90*i)),\n",
        "                                    tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                    tr.ToTensor(),\n",
        "                                    tr.RandomVerticalFlip(p=1)]))\n",
        "    for i in range(4):\n",
        "        transform_list_train.append(tr.Compose([tr.ToPILImage(),\n",
        "                                    tr.RandomRotation((90*i,90*i)),\n",
        "                                    tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                    tr.ToTensor(),\n",
        "                                    tr.RandomHorizontalFlip(p=1),\n",
        "                                    tr.RandomVerticalFlip(p=1)]))\n",
        "    data_transform_list = transform_list_train\n",
        "\n",
        "\n",
        "else:\n",
        "    transform_list_test=[tr.Compose([tr.ToPILImage(),\n",
        "                                    tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                    tr.ToTensor()])]\n",
        "    transform_list_train=[tr.Compose([tr.ToPILImage(),\n",
        "                                    tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                    tr.ToTensor()])]\n",
        "\n",
        "\n",
        "dataset = MyDataset(img_path=PATH_TO_DATASET_IMAGES, label_path=PATH_TO_DATASET_LABELS, transform=transform_list_test, allDataset = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC-ec6_mdF7Y",
        "outputId": "0cd689e8-cef9-4679-aa16-73ca4be2caeb"
      },
      "outputs": [],
      "source": [
        "# apply data augmentation\n",
        "if DATA_AUG:\n",
        "    train_dataset = MyDataset(img_path=PATH_TO_TRAIN_DATASET_IMAGES, label_path=PATH_TO_TRAIN_DATASET_LABEL, transform=transform_list_train)\n",
        "else:\n",
        "    train_dataset = MyDataset(img_path=PATH_TO_TRAIN_DATASET_IMAGES, label_path=PATH_TO_TRAIN_DATASET_LABEL, transform=transform_list_test)\n",
        "\n",
        "val_dataset = MyDataset(img_path=PATH_TO_VAL_DATASET_IMAGES, label_path=PATH_TO_VAL_DATASET_LABEL, transform=transform_list_test)\n",
        "test_dataset = MyDataset(img_path=PATH_TO_TEST_DATASET_IMAGES, label_path=PATH_TO_TEST_DATASET_LABEL, transform=transform_list_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calculate mean and std of the dataset for normalization\n",
        "if NORMALISE_IMGS:\n",
        "    mean_train_set = torch.mean(dataset.data, dim=(0, 2, 3), keepdim=True)\n",
        "    std_train_set = torch.std(dataset.data, dim=(0, 2, 3), keepdim=True)\n",
        "\n",
        "    train_dataset.data = (train_dataset.data - mean_train_set) / std_train_set\n",
        "    val_dataset.data = (val_dataset.data - mean_train_set) / std_train_set\n",
        "    test_dataset.data = (test_dataset.data - mean_train_set) / std_train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "print('DATALOADERS OK')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture\n",
        "\n",
        "The **U-Ne**t is a popular convolutional neural network (CNN) architecture specifically designed for semantic segmentation tasks. It was first introduced by Olaf Ronneberger, Philipp Fischer, and Thomas Brox in 2015. The U-Net architecture is widely used and has achieved state-of-the-art results in various image segmentation challenges.\n",
        "\n",
        "The unique aspect of the U-Net architecture is its U-shaped or symmetric structure, which consists of an encoder path and a corresponding decoder path. The encoder path captures context and extracts high-level features from the input image, while the decoder path performs precise localization by upsampling and concatenating the features from the encoder path.\n",
        "\n",
        "The encoder path of the U-Net architecture follows a typical CNN design, with successive convolutional and pooling layers to downsample the spatial dimensions of the input image. This allows the network to capture increasingly abstract and high-level features while reducing the spatial resolution.\n",
        "\n",
        "The decoder path of the U-Net architecture employs upsampling operations, such as transposed convolutions or bilinear interpolation, to gradually recover the spatial resolution lost during the encoding phase. The feature maps from the encoder path are concatenated with the corresponding feature maps in the decoder path using skip connections. These skip connections help to preserve fine-grained spatial information and provide local context for accurate segmentation.\n",
        "\n",
        "The U-Net architecture is particularly effective for tasks like biomedical image segmentation, where the objects of interest are often small and surrounded by complex backgrounds. By combining both local and global information, the U-Net can produce segmentation maps with precise object boundaries and handle class imbalance issues.\n",
        "\n",
        "Due to its architecture's effectiveness and versatility, the U-Net has been widely adopted in various domains, including medical image analysis, satellite image segmentation, and general computer vision applications. It has become a popular choice for researchers and practitioners working on semantic segmentation tasks, offering a powerful tool for pixel-wise classification and accurate object delineation.\n",
        "\n",
        "<div style=\"text-align:center\">\n",
        "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=\"600\"  />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1cDoWAqdF7Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "\n",
        "class DoubleConvolution(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(DoubleConvolution, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, input_channels=3, output_channels=6,\n",
        "                 features=[64, 128, 256, 512]):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Encoder\n",
        "        for f in features:\n",
        "            self.downs.append(DoubleConvolution(input_channels, f))\n",
        "            input_channels = f\n",
        "\n",
        "        # lower bottleneck layers\n",
        "        self.bottleneck = DoubleConvolution(features[-1], features[-1] * 2)\n",
        "\n",
        "        # Decoder\n",
        "        for f in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Upsample(scale_factor=2),\n",
        "                    nn.Conv2d(in_channels=2 * f, out_channels=f, kernel_size=3,\n",
        "                              padding=1),\n",
        "                ))\n",
        "            self.ups.append(DoubleConvolution(2 * f, f))\n",
        "\n",
        "        self.final_convolution = nn.Conv2d(in_channels=features[0],\n",
        "                                           out_channels=output_channels,\n",
        "                                           kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = list()\n",
        "        for module in self.downs:\n",
        "            x = module(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        skip_connections = skip_connections[::-1]  # reverse order\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        for i in range(0, len(self.ups), 2):\n",
        "            x = self.ups[i](x)\n",
        "            skip_connection = skip_connections[i // 2]\n",
        "            if skip_connection.shape != x.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:],\n",
        "                              interpolation=TF.InterpolationMode.NEAREST)\n",
        "            x = torch.cat([skip_connection, x], dim=1)\n",
        "            x = self.ups[i + 1](x)\n",
        "\n",
        "        x = self.final_convolution(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiPQ6n9-dF7a"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "def train(model, optimizer, loss_fn, train_loader, epochs=20, device='cuda'):\n",
        "\n",
        "    train_loss_list = []\n",
        "    epoch_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        training_loss = 0.0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = loss_fn(output, targets.squeeze(1))  # modify\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        model.eval()\n",
        "\n",
        "        print('Epoch: {}, Training Loss: {:.4f}'.format(epoch, training_loss))\n",
        "        train_loss_list.append(training_loss)\n",
        "        epoch_list.append(epoch)\n",
        "\n",
        "    return model, optimizer, (train_loss_list, epoch_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCmxeX8YdF7b"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, device='cuda'):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    num_correct = 0\n",
        "    num_examples = 0\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "    for batch in test_loader:\n",
        "        inputs, targets = batch\n",
        "        inputs = inputs.to(device)\n",
        "        output = model(inputs)\n",
        "        targets = targets.to(device)\n",
        "        loss = loss_fn(output, targets.squeeze(1))  # modify\n",
        "        test_loss += loss.data.item() * inputs.size(0)\n",
        "\n",
        "        # Convert output probabilities to predicted labels\n",
        "        _, predicted = torch.max(output, dim=1)\n",
        "        predicted_labels.extend(predicted.cpu())\n",
        "        true_labels.extend(targets.cpu())\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('Test Loss: {:.4f}'.format(test_loss))\n",
        "\n",
        "    return test_loss, predicted_labels, true_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFbDaUE4dF7c"
      },
      "source": [
        "## Validation Test with few images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "rxSdYgVxdF7d",
        "outputId": "98883780-0fbe-4fb0-9f29-6e0251d5f61e"
      },
      "outputs": [],
      "source": [
        "model = UNet(input_channels=3, output_channels=6)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "class_counts = torch.bincount(dataset.labels.flatten())\n",
        "print(class_counts)\n",
        "\n",
        "class_weights = 1.0 / class_counts.float()\n",
        "class_weights /= torch.sum(class_weights)\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "print(class_weights)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train\n",
        "model, optimizer, (train_loss_list, epoch_list) = train(model, optimizer, loss_fn, train_dataloader, epochs=N_EPOCHS, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# validation\n",
        "val_loss, predicted_labels_val, true_labels_val = test(model, val_dataloader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr1q6KuKlQ4o"
      },
      "outputs": [],
      "source": [
        "for i in range (len(true_labels_val)):\n",
        "    true_labels_val[i] = true_labels_val[i].numpy()\n",
        "for i in range (len(predicted_labels_val)):\n",
        "    predicted_labels_val[i] = predicted_labels_val[i].numpy()\n",
        "\n",
        "true_labels_val = np.array(true_labels_val)\n",
        "true_labels_val = np.squeeze(true_labels_val)\n",
        "\n",
        "\n",
        "predicted_labels_val = np.array(predicted_labels_val).flatten()\n",
        "true_labels_val = np.array(true_labels_val).flatten()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(true_labels_val, predicted_labels_val))\n",
        "print(\"Precision:\", precision_score(true_labels_val, predicted_labels_val, average='weighted'))\n",
        "print(\"Recall:\", recall_score(true_labels_val, predicted_labels_val, average='weighted'))\n",
        "print(\"F1:\", f1_score(true_labels_val, predicted_labels_val, average='weighted'))\n",
        "\n",
        "# print confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(true_labels_val, predicted_labels_val)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "\n",
        "# print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(true_labels_val, predicted_labels_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKdX60K3dF7e"
      },
      "source": [
        "## Validation Set with a lot of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1iKGTe3dF7f",
        "outputId": "0fba2cd2-6ce5-47e9-e432-85d1b866be65"
      },
      "outputs": [],
      "source": [
        "transform_list_train=[]\n",
        "for i in range(4):\n",
        "    transform_list_train.append(tr.Compose([tr.ToPILImage(),\n",
        "                                tr.RandomRotation((90*i,90*i)),\n",
        "                                tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                tr.ToTensor()]))\n",
        "for i in range(4):\n",
        "    transform_list_train.append(tr.Compose([tr.ToPILImage(),\n",
        "                                tr.RandomRotation((90*i,90*i)),\n",
        "                                tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                tr.ToTensor(),\n",
        "                                tr.RandomHorizontalFlip(p=1)]))\n",
        "for i in range(4):\n",
        "    transform_list_train.append(tr.Compose([tr.ToPILImage(),\n",
        "                                tr.RandomRotation((90*i,90*i)),\n",
        "                                tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                tr.ToTensor(),\n",
        "                                tr.RandomVerticalFlip(p=1)]))\n",
        "for i in range(4):\n",
        "    transform_list_train.append(tr.Compose([tr.ToPILImage(),\n",
        "                                tr.RandomRotation((90*i,90*i)),\n",
        "                                tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "                                tr.ToTensor(),\n",
        "                                tr.RandomHorizontalFlip(p=1),\n",
        "                                tr.RandomVerticalFlip(p=1)]))\n",
        "\n",
        "\n",
        "train_dataset = MyDataset(img_path=PATH_TO_TRAIN_DATASET_IMAGES, label_path=PATH_TO_TRAIN_DATASET_LABEL, transform=transform_list_train)\n",
        "train_dataset.data = (train_dataset.data - mean_train_set) / std_train_set\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = UNet(input_channels=3, output_channels=6)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "class_counts = torch.bincount(dataset.labels.flatten())\n",
        "print(class_counts)\n",
        "\n",
        "class_weights = 1.0 / class_counts.float()\n",
        "class_weights /= torch.sum(class_weights)\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "print(class_weights)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rBOOskNY1LW",
        "outputId": "d784667f-e378-4f37-ab2c-1fc65e3ae981"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "model, optimizer, (train_loss_list, epoch_list) = train(model, optimizer, loss_fn, train_dataloader, epochs=N_EPOCHS, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# val\n",
        "val_loss, predicted_labels_val, true_labels_val = test(model, val_dataloader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "tZYShHSVY4Kb",
        "outputId": "fdad942e-e69a-4f99-ce26-cc32c909ac5d"
      },
      "outputs": [],
      "source": [
        "for i in range (len(true_labels_val)):\n",
        "    true_labels_val[i] = true_labels_val[i].numpy()\n",
        "for i in range (len(predicted_labels_val)):\n",
        "    predicted_labels_val[i] = predicted_labels_val[i].numpy()\n",
        "\n",
        "true_labels_val = np.array(true_labels_val)\n",
        "true_labels_val = np.squeeze(true_labels_val)\n",
        "\n",
        "\n",
        "predicted_labels_val = np.array(predicted_labels_val).flatten()\n",
        "true_labels_val = np.array(true_labels_val).flatten()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(true_labels_val, predicted_labels_val))\n",
        "print(\"Precision:\", precision_score(true_labels_val, predicted_labels_val, average='weighted'))\n",
        "print(\"Recall:\", recall_score(true_labels_val, predicted_labels_val, average='weighted'))\n",
        "print(\"F1:\", f1_score(true_labels_val, predicted_labels_val, average='weighted'))\n",
        "\n",
        "# print confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(true_labels_val, predicted_labels_val)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "\n",
        "# print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(true_labels_val, predicted_labels_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHcdVJUfdF7f"
      },
      "source": [
        "## Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8yGDQyldF7g",
        "outputId": "92f25f54-f6b2-429a-897b-62c73ecc4b55"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "test_loss, predicted_labels_test, true_labels_test = test(model, val_dataloader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PW-ZtOgYdF7g",
        "outputId": "386d9f5b-e3c4-4893-88ea-0da2f8e90be2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# test\n",
        "predicted_labels_test_rgb = [dataset.revert_image(label) for label in predicted_labels_test]\n",
        "true_labels_test_rgb = [dataset.revert_image(label[0]) for label in true_labels_test]\n",
        "\n",
        "if len(predicted_labels_test_rgb) == 1:\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
        "\n",
        "    axes[0].imshow(predicted_labels_test_rgb[0].permute(1,2,0))\n",
        "    axes[0].set_title(\"Predicted Label test\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    original_img = dataset.revert_image(dataset.labels[0].reshape(PATCH_SIDE, PATCH_SIDE)).permute(1,2,0)\n",
        "    axes[1].imshow(original_img)\n",
        "    axes[1].set_title(\"Original Label\")\n",
        "    axes[1].axis('off')\n",
        "else:\n",
        "    fig, axes = plt.subplots(nrows=len(predicted_labels_test_rgb), ncols=2, figsize=(10, len(predicted_labels_test_rgb)*5))\n",
        "\n",
        "    for i in range(len(predicted_labels_test_rgb)):\n",
        "        axes[i, 0].imshow(predicted_labels_test_rgb[i].permute(1,2,0))\n",
        "        axes[i, 0].set_title(\"Predicted Label Test\")\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # original_img = dataset.revert_image(true_labels_train_rgb[i].permute(1,2,0)\n",
        "        axes[i, 1].imshow(true_labels_test_rgb[i].permute(1,2,0))\n",
        "        # axes[i, 1].imshow(original_img)\n",
        "        axes[i, 1].set_title(\"Original Label Test\")\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "reTKcXwbdF7h",
        "outputId": "76e8bc34-ef8f-4b34-8448-8d37d52d0298"
      },
      "outputs": [],
      "source": [
        "plt.plot(epoch_list, train_loss_list, label='Train Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wYP08iDdF7h",
        "outputId": "da72953e-44ec-4e34-97c9-a7e168af2bc7"
      },
      "outputs": [],
      "source": [
        "for i in range (len(true_labels_test)):\n",
        "    true_labels_test[i] = true_labels_test[i].numpy()\n",
        "for i in range (len(predicted_labels_test)):\n",
        "    predicted_labels_test[i] = predicted_labels_test[i].numpy()\n",
        "\n",
        "true_labels_test = np.array(true_labels_test)\n",
        "true_labels_test = np.squeeze(true_labels_test)\n",
        "print(np.shape(true_labels_test))\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "predicted_labels_test = np.array(predicted_labels_test).flatten()\n",
        "true_labels_test = np.array(true_labels_test).flatten()\n",
        "\n",
        "# Count the occurrences of each class label\n",
        "predicted_counts = np.bincount(predicted_labels_test)\n",
        "true_counts = np.bincount(true_labels_test)\n",
        "\n",
        "# Print the counts\n",
        "for label, count in enumerate(predicted_counts):\n",
        "    print(f\"Predicted label {label}: {count} occurrences\")\n",
        "\n",
        "for label, count in enumerate(true_counts):\n",
        "    print(f\"True label {label}: {count} occurrences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "MpxEW5rPdF7h",
        "outputId": "93ad9272-0de5-4308-c751-63d332c7c10f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "true_labels_test = np.array(true_labels_test)\n",
        "true_labels_test = np.squeeze(true_labels_test)\n",
        "\n",
        "# print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(true_labels_test, predicted_labels_test, ))\n",
        "print(\"Precision:\", precision_score(true_labels_test, predicted_labels_test, average='weighted'))\n",
        "print(\"Recall:\", recall_score(true_labels_test, predicted_labels_test, average='weighted'))\n",
        "print(\"F1:\", f1_score(true_labels_test, predicted_labels_test, average='weighted'))\n",
        "\n",
        "# print confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(true_labels_test, predicted_labels_test)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "\n",
        "# print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(true_labels_test, predicted_labels_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
